{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ed2df0-2592-4545-97fa-949c22a9dd88",
   "metadata": {},
   "source": [
    "# 13th April Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5cfe2-bec3-42dd-944e-8686ce9f8c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bddfed96-77b7-4325-95ad-1e0f315a3d0a",
   "metadata": {},
   "source": [
    "## Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ffca1-35b9-448b-a296-635c68b660af",
   "metadata": {},
   "source": [
    "- > Random forest regressor is a technique of bagging.\n",
    "\n",
    "- > We use multiple decision tree regressor for train and test data.\n",
    "\n",
    "- > As a final prediction we calculate average of all model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3a173-339c-4f18-a1ae-df31917e062e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b99878c-82ac-4392-90be-a34c04f4016f",
   "metadata": {},
   "source": [
    "## Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe1223-5c0b-4f1a-b76a-3038cd6dbf15",
   "metadata": {},
   "source": [
    "- > We assign different bootsrap samples to the different decision tree.\n",
    "\n",
    "- > Because of it trees become diversify and it helps prevent the model from memorizing the training data.\n",
    "\n",
    "- > Random forest also limits the maximum depth of individual tree.It prevents the model from noise.\n",
    "\n",
    "- > This technique also has feature name out-of-bag-score.When we assign diiferent boostrap samples randomly to the models so some data remains unassigned.Random forest use\n",
    "    that data as validation.It helps to get natural estimation of model on unseen data.\n",
    "    \n",
    "- > Random forest also have hyperparameters like number of trees,maximum depth and minimum samples for split which can be tuned to control model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccf660-19ee-4918-a8e7-a0fade162ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196c5dc5-375d-4af7-be9a-f4d897b82fad",
   "metadata": {},
   "source": [
    "## Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4631678-948a-446e-aecf-5a2606d0c74d",
   "metadata": {},
   "source": [
    "- > By calculating the mean or median of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73e208-47f9-4511-8cd7-94da50203588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4684c4a-fb04-47c9-ad4b-9f064676e94f",
   "metadata": {},
   "source": [
    "## Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b675a-08dc-498d-a394-5f398475f220",
   "metadata": {},
   "source": [
    "1. Number of trees\n",
    "\n",
    "2. Maximum depth\n",
    "\n",
    "3. Mininum samples for split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564cac0-b303-4930-99b2-56fd732fd81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b828dd60-0bdd-4b93-89e9-0b8f0486f68f",
   "metadata": {},
   "source": [
    "## Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a1c10-2756-4f1b-898f-85d45a6264e6",
   "metadata": {},
   "source": [
    "* Model\n",
    "\n",
    "Random Forest - > Random forest regressor uses multiple models.\n",
    "\n",
    "Cecision Tree ->  Decision tree regressor uses only one model.\n",
    "\n",
    "* Training the Data\n",
    "\n",
    "Random Forest - > Trains multiple decision trees individualy.\n",
    "\n",
    "Decision Tree - > Trained by recursively splitting the data based on features.\n",
    "\n",
    "* Overfitting\n",
    "\n",
    "Random Forest - > It is used to solve the problem of overfitting by saperatly training the multiple decision trees.\n",
    "\n",
    "Decision Tree - > Model can overfit by deep trees.\n",
    "\n",
    "* Prediction\n",
    "\n",
    "Random Forest - > Predicts the target value by aggregating the predictions of individual models.\n",
    "\n",
    "Decision Tree - > Predicts the target value by traversing the tree from root to leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27694158-2290-47dc-992a-ce9ab93a175a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e154ce86-59c0-4c87-b2c7-6dfdbd259c8b",
   "metadata": {},
   "source": [
    "## Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe4597-1a31-418f-ade3-1247a9f98275",
   "metadata": {},
   "source": [
    "* Advantages\n",
    "\n",
    "- > Highly accurate.\n",
    "\n",
    "- > Reduce the variance.\n",
    "\n",
    "- > Random forest can be applied on different types of data.\n",
    "\n",
    "- > It is robust to outliers.\n",
    "\n",
    "* Disadvantages\n",
    "\n",
    "- > It is complex to compute.\n",
    "\n",
    "- > Random forest can consume large memory when number of trees are significant.\n",
    "\n",
    "- > Random forest are sensitive to noisy data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6b98a-86aa-482d-91ef-61018c1e1c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e48b432-1efb-49b0-a034-28a1d4ecb369",
   "metadata": {},
   "source": [
    "## Q7. What is the output of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afbb84-4fc2-401a-9e3f-9c84ee965397",
   "metadata": {},
   "source": [
    "- > The output is prediction of target value and it is a continues numeric value.\n",
    "\n",
    "- > The final output of it is aggregation of predictions from multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91d300-3801-4d58-9448-b47e8cdc33e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee3f610-774e-42ae-8de1-63b70ee4662b",
   "metadata": {},
   "source": [
    "## Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1437d-e942-422f-9e7a-0dc34a8d8184",
   "metadata": {},
   "source": [
    "- > It can be adapted for classification problem by some modification.\n",
    "\n",
    "- > It involves converting problem into binary classification or use random forest classification that is specifically designed classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
